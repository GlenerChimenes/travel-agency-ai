# Configura a URL base do servidor Ollama.
quarkus.langchain4j.ollama.base-url=http://localhost:11434/

# Define o ID do modelo que o Langchain4j irá invocar no Ollama.
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2:latest

# Define um timeout para a chamada.
# Se o modelo demorar mais de 60s para responder, a chamada falhará.
quarkus.langchain4j.ollama.timeout=240s

quarkus.langchain4j.easy-rag.path=src/main/resources/rag